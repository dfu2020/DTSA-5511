# DTSA5511 Week 4 Project
This is the public repository for the week 4 Mini Kaggle Competition Project.

**Table of Contents**

## What's included
In this GIT repository, you will find the following items:

1. [DTSA_5511_week4.ipynb](DTSA_5511_week4.ipynb) is the jupyter notebook of this project.
2. [week4_NLP_Prediction_submission.csv](week4_NLP_Prediction_submission.csv) is the output prediction submission .csv consisting of tweet 'id' and 'target' that has been submitted to the Kaggle Competition.
3. [week4_submission_Kaggle_score.png](week4_submission_Kaggle_score.png) is the screenshot of the Kaggle public and private score.


## Project Summary
In this week's project, we are participating in Kaggle's competition. We will build a recurrent neural network (RNN) [https://en.wikipedia.org/wiki/Recurrent_neural_network]. This will be implemented using 
tensorflow keras sequential model [https://www.tensorflow.org/guide/keras/sequential_model].

The data comes from Kaggle Competition: Addison Howard, devrishi, Phil Culliton, Yufeng Guo. (2019). Natural Language Processing with Disaster Tweets. Kaggle. https://kaggle.com/competitions/nlp-getting-started

Since we are working with natural language processing, we will make use of the python natural language toolkit [https://github.com/nltk/nltk/wiki] to perform some simple natural language processing (i.e., text cleaning and reformatting).

In the model training procedure, we will focus on tuning the RNN model's initial learning rate and activation function to achieve a best model performance. Finally, we will conclude what we have learnt from this project.
